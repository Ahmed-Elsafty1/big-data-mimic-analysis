{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4912a7c5-920e-4822-9beb-d98ad6f0ab83",
   "metadata": {},
   "source": [
    "## Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a000c6-3480-40a9-bb33-41559d47f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import avro.schema\n",
    "from avro.datafile import DataFileWriter\n",
    "from avro.io import DatumWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c2acb",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69982ca-3c1a-40eb-aa34-3af56db51f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission = pd.read_csv('ADMISSIONS.csv')\n",
    "patient = pd.read_csv('PATIENTS.csv')\n",
    "services = pd.read_csv('SERVICES.csv')\n",
    "transferes = pd.read_csv('TRANSFERS.csv')\n",
    "labeventes = pd.read_csv('LABEVENTS.csv')\n",
    "icustay = pd.read_csv('ICUSTAYS.csv')\n",
    "dignoses_icd = pd.read_csv('DIAGNOSES_ICD.csv')\n",
    "d_labitems = pd.read_csv('D_LABITEMS.csv')\n",
    "d_icd_dignoses = pd.read_csv('D_ICD_DIAGNOSES.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370bd8e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4c72f",
   "metadata": {},
   "source": [
    "### Table --> admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb67de28-73e0-4788-ba05-0e61932fc156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>has_chartevents_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12258</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>2164-11-01 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SEPARATED</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2164-10-23 16:43:00</td>\n",
       "      <td>2164-10-23 23:00:00</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12263</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12265</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12269</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>2149-06-03 18:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2149-05-26 12:08:00</td>\n",
       "      <td>2149-05-26 19:45:00</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12270</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id            admittime            dischtime  \\\n",
       "0   12258       10006   142345  2164-10-23 21:09:00  2164-11-01 17:15:00   \n",
       "1   12263       10011   105331  2126-08-14 22:32:00  2126-08-28 18:59:00   \n",
       "2   12265       10013   165520  2125-10-04 23:36:00  2125-10-07 15:13:00   \n",
       "3   12269       10017   199207  2149-05-26 17:19:00  2149-06-03 18:42:00   \n",
       "4   12270       10019   177759  2163-05-14 20:43:00  2163-05-15 12:00:00   \n",
       "\n",
       "             deathtime admission_type         admission_location  \\\n",
       "0                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1  2126-08-28 18:59:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "2  2125-10-07 15:13:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "3                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "4  2163-05-15 12:00:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "  discharge_location insurance language  religion marital_status  \\\n",
       "0   HOME HEALTH CARE  Medicare      NaN  CATHOLIC      SEPARATED   \n",
       "1       DEAD/EXPIRED   Private      NaN  CATHOLIC         SINGLE   \n",
       "2       DEAD/EXPIRED  Medicare      NaN  CATHOLIC            NaN   \n",
       "3                SNF  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "4       DEAD/EXPIRED  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "\n",
       "                ethnicity            edregtime            edouttime  \\\n",
       "0  BLACK/AFRICAN AMERICAN  2164-10-23 16:43:00  2164-10-23 23:00:00   \n",
       "1   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "2   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "3                   WHITE  2149-05-26 12:08:00  2149-05-26 19:45:00   \n",
       "4                   WHITE                  NaN                  NaN   \n",
       "\n",
       "             diagnosis  hospital_expire_flag  has_chartevents_data  \n",
       "0               SEPSIS                     0                     1  \n",
       "1          HEPATITIS B                     1                     1  \n",
       "2               SEPSIS                     1                     1  \n",
       "3     HUMERAL FRACTURE                     0                     1  \n",
       "4  ALCOHOLIC HEPATITIS                     1                     1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e58c0e0-1122-46ad-a04e-f4160e923750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   row_id                129 non-null    int64 \n",
      " 1   subject_id            129 non-null    int64 \n",
      " 2   hadm_id               129 non-null    int64 \n",
      " 3   admittime             129 non-null    object\n",
      " 4   dischtime             129 non-null    object\n",
      " 5   deathtime             40 non-null     object\n",
      " 6   admission_type        129 non-null    object\n",
      " 7   admission_location    129 non-null    object\n",
      " 8   discharge_location    129 non-null    object\n",
      " 9   insurance             129 non-null    object\n",
      " 10  language              81 non-null     object\n",
      " 11  religion              128 non-null    object\n",
      " 12  marital_status        113 non-null    object\n",
      " 13  ethnicity             129 non-null    object\n",
      " 14  edregtime             92 non-null     object\n",
      " 15  edouttime             92 non-null     object\n",
      " 16  diagnosis             129 non-null    object\n",
      " 17  hospital_expire_flag  129 non-null    int64 \n",
      " 18  has_chartevents_data  129 non-null    int64 \n",
      "dtypes: int64(5), object(14)\n",
      "memory usage: 19.3+ KB\n"
     ]
    }
   ],
   "source": [
    "admission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff01df-66d6-4770-b25d-44a93e499eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Admission\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"admittime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"dischtime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"deathtime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"admission_type\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"admission_location\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"discharge_location\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"insurance\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"language\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"religion\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"marital_status\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"ethnicity\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"edregtime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"edouttime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"diagnosis\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"hospital_expire_flag\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"has_chartevents_data\", \"type\": [\"int\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = pd.read_csv('ADMISSIONS.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert timestamp columns to datetime64[ns]\n",
    "timestamp_columns = [\"admittime\", \"dischtime\", \"deathtime\", \"edregtime\", \"edouttime\"]\n",
    "for col in timestamp_columns:\n",
    "    if col in df.columns:\n",
    "        # Assuming string format like 'YYYY-MM-DD HH:MM:SS'; adjust format if different\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "for col in ['row_id', 'subject_id', 'hadm_id', 'hospital_expire_flag', 'has_chartevents_data']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\n",
    "    'admission_type', 'admission_location', 'discharge_location', \n",
    "    'insurance', 'language', 'religion', 'marital_status', 'ethnicity', 'diagnosis'\n",
    "]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in timestamp_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"admissions.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70c995-1ea6-4d93-a20d-be34fde00c32",
   "metadata": {},
   "source": [
    "### Table --> patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Patient\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"gender\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"dob\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"dod\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"dod_hosp\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"dod_ssn\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"expire_flag\", \"type\": [\"int\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = patient\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert date columns to Timestamp\n",
    "date_columns = [\"dob\", \"dod\", \"dod_hosp\", \"dod_ssn\"]\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        # Adjust format or unit based on your data (e.g., 'ms' for milliseconds, 's' for seconds)\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', unit='ms' if df[col].dtype == 'int64' else None)\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "for col in ['row_id', 'subject_id', 'expire_flag']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0 or adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "if 'gender' in df.columns:\n",
    "    df['gender'] = df['gender'].fillna('')  # Fill NA with empty string\n",
    "else:\n",
    "    raise ValueError(\"Column gender not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in date_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "#C:\\Users\\ahmed\\OneDrive\\Desktop\\w\\avrotest\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"w\",\"avrotest\",\"patients.avro\")\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aeb28e-ea57-4c7c-af16-8cc7f9070d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ddabb7e-41d4-440e-a6f1-4a6737144855",
   "metadata": {},
   "source": [
    "### Table --> icustay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6632a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   row_id          136 non-null    int64  \n",
      " 1   subject_id      136 non-null    int64  \n",
      " 2   hadm_id         136 non-null    int64  \n",
      " 3   icustay_id      136 non-null    int64  \n",
      " 4   dbsource        136 non-null    object \n",
      " 5   first_careunit  136 non-null    object \n",
      " 6   last_careunit   136 non-null    object \n",
      " 7   first_wardid    136 non-null    int64  \n",
      " 8   last_wardid     136 non-null    int64  \n",
      " 9   intime          136 non-null    object \n",
      " 10  outtime         136 non-null    object \n",
      " 11  los             136 non-null    float64\n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 12.9+ KB\n"
     ]
    }
   ],
   "source": [
    "icustay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d426f1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>dbsource</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>last_careunit</th>\n",
       "      <th>first_wardid</th>\n",
       "      <th>last_wardid</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12742</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>206504</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2164-10-23 21:10:15</td>\n",
       "      <td>2164-10-25 12:21:07</td>\n",
       "      <td>1.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12747</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>232110</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2126-08-14 22:34:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>13.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12749</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>264446</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2125-10-04 23:38:00</td>\n",
       "      <td>2125-10-07 15:13:52</td>\n",
       "      <td>2.6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12754</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>204881</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2149-05-29 18:52:29</td>\n",
       "      <td>2149-05-31 22:19:17</td>\n",
       "      <td>2.1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12755</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>228977</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2163-05-14 20:43:56</td>\n",
       "      <td>2163-05-16 03:47:04</td>\n",
       "      <td>1.2938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id  icustay_id dbsource first_careunit  \\\n",
       "0   12742       10006   142345      206504  carevue           MICU   \n",
       "1   12747       10011   105331      232110  carevue           MICU   \n",
       "2   12749       10013   165520      264446  carevue           MICU   \n",
       "3   12754       10017   199207      204881  carevue            CCU   \n",
       "4   12755       10019   177759      228977  carevue           MICU   \n",
       "\n",
       "  last_careunit  first_wardid  last_wardid               intime  \\\n",
       "0          MICU            52           52  2164-10-23 21:10:15   \n",
       "1          MICU            15           15  2126-08-14 22:34:00   \n",
       "2          MICU            15           15  2125-10-04 23:38:00   \n",
       "3           CCU             7            7  2149-05-29 18:52:29   \n",
       "4          MICU            15           15  2163-05-14 20:43:56   \n",
       "\n",
       "               outtime      los  \n",
       "0  2164-10-25 12:21:07   1.6325  \n",
       "1  2126-08-28 18:59:00  13.8507  \n",
       "2  2125-10-07 15:13:52   2.6499  \n",
       "3  2149-05-31 22:19:17   2.1436  \n",
       "4  2163-05-16 03:47:04   1.2938  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icustay.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 12742, 'subject_id': 10006, 'hadm_id': 142345, 'icustay_id': 206504, 'dbsource': 'carevue', 'first_careunit': 'MICU', 'last_careunit': 'MICU', 'first_wardid': 52, 'last_wardid': 52, 'intime': datetime.datetime(2164, 10, 23, 21, 10, 15, tzinfo=datetime.timezone.utc), 'outtime': datetime.datetime(2164, 10, 25, 12, 21, 7, tzinfo=datetime.timezone.utc), 'los': 1.6325}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"ICUStay\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"icustay_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"dbsource\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"first_careunit\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"last_careunit\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"first_wardid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"last_wardid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"intime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"outtime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"los\", \"type\": [\"double\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = icustay #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert timestamp columns to datetime64[ns]\n",
    "timestamp_columns = [\"intime\", \"outtime\"]\n",
    "for col in timestamp_columns:\n",
    "    if col in df.columns:\n",
    "        # Assuming string format like 'YYYY-MM-DD HH:MM:SS'; adjust format if different\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"subject_id\", \"hadm_id\", \"icustay_id\", \"first_wardid\", \"last_wardid\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"dbsource\", \"first_careunit\", \"last_careunit\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert los to float64 and handle missing values\n",
    "if 'los' in df.columns:\n",
    "    df['los'] = df['los'].fillna(0.0).astype('float64')  # Fill NA with 0.0; adjust as needed\n",
    "else:\n",
    "    raise ValueError(\"Column los not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in timestamp_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"icustay_id.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa7e38-1f28-4862-a8c7-8e90dbaf08fa",
   "metadata": {},
   "source": [
    "### Table --> dignoses_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892b97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1761 entries, 0 to 1760\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   row_id      1761 non-null   int64 \n",
      " 1   subject_id  1761 non-null   int64 \n",
      " 2   hadm_id     1761 non-null   int64 \n",
      " 3   seq_num     1761 non-null   int64 \n",
      " 4   icd9_code   1761 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 68.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dignoses_icd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d7e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 112344, 'subject_id': 10006, 'hadm_id': 142345, 'seq_num': 1, 'icd9_code': '99591'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Diagnosis\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"seq_num\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"icd9_code\", \"type\": [\"string\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = dignoses_icd #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"subject_id\", \"hadm_id\", \"seq_num\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string column and handle missing values\n",
    "if 'icd9_code' in df.columns:\n",
    "    df['icd9_code'] = df['icd9_code'].fillna('').astype('string')  # Fill NA with empty string\n",
    "else:\n",
    "    raise ValueError(\"Column icd9_code not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"diagnoses.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf519b",
   "metadata": {},
   "source": [
    "### Table --> services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d53d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163 entries, 0 to 162\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   row_id        163 non-null    int64 \n",
      " 1   subject_id    163 non-null    int64 \n",
      " 2   hadm_id       163 non-null    int64 \n",
      " 3   transfertime  163 non-null    object\n",
      " 4   prev_service  34 non-null     object\n",
      " 5   curr_service  163 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 7.8+ KB\n"
     ]
    }
   ],
   "source": [
    "services.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26d75a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>transfertime</th>\n",
       "      <th>prev_service</th>\n",
       "      <th>curr_service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14974</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:10:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14979</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:34:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14981</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14985</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:21:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14986</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id         transfertime prev_service curr_service\n",
       "0   14974       10006   142345  2164-10-23 21:10:15          NaN          MED\n",
       "1   14979       10011   105331  2126-08-14 22:34:00          NaN          MED\n",
       "2   14981       10013   165520  2125-10-04 23:38:00          NaN          MED\n",
       "3   14985       10017   199207  2149-05-26 17:21:09          NaN          MED\n",
       "4   14986       10019   177759  2163-05-14 20:43:56          NaN          MED"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 14974, 'subject_id': 10006, 'hadm_id': 142345, 'transfertime': datetime.datetime(2164, 10, 23, 21, 10, 15, tzinfo=datetime.timezone.utc), 'prev_service': '', 'curr_service': 'MED'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Transfer\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"transfertime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"prev_service\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"curr_service\", \"type\": [\"string\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = services  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert timestamp column to datetime64[ns]\n",
    "timestamp_columns = [\"transfertime\"]\n",
    "for col in timestamp_columns:\n",
    "    if col in df.columns:\n",
    "        # Assuming string format like 'YYYY-MM-DD HH:MM:SS'; adjust format if different\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"subject_id\", \"hadm_id\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"prev_service\", \"curr_service\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in timestamp_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"transfers.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d7ddc",
   "metadata": {},
   "source": [
    "### Table --> transferes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7939b13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 524 entries, 0 to 523\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   row_id         524 non-null    int64  \n",
      " 1   subject_id     524 non-null    int64  \n",
      " 2   hadm_id        524 non-null    int64  \n",
      " 3   icustay_id     167 non-null    float64\n",
      " 4   dbsource       524 non-null    object \n",
      " 5   eventtype      524 non-null    object \n",
      " 6   prev_careunit  167 non-null    object \n",
      " 7   curr_careunit  167 non-null    object \n",
      " 8   prev_wardid    395 non-null    float64\n",
      " 9   curr_wardid    395 non-null    float64\n",
      " 10  intime         524 non-null    object \n",
      " 11  outtime        395 non-null    object \n",
      " 12  los            395 non-null    float64\n",
      "dtypes: float64(4), int64(3), object(6)\n",
      "memory usage: 53.3+ KB\n"
     ]
    }
   ],
   "source": [
    "transferes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 54440, 'subject_id': 10006, 'hadm_id': 142345, 'icustay_id': 206504, 'dbsource': 'carevue', 'eventtype': 'admit', 'prev_careunit': '', 'curr_careunit': 'MICU', 'prev_wardid': 0, 'curr_wardid': 52, 'intime': datetime.datetime(2164, 10, 23, 21, 10, 15, tzinfo=datetime.timezone.utc), 'outtime': datetime.datetime(2164, 10, 25, 12, 21, 7, tzinfo=datetime.timezone.utc), 'los': 39.18}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"CareEvent\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"icustay_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"dbsource\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"eventtype\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"prev_careunit\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"curr_careunit\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"prev_wardid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"curr_wardid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"intime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"outtime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"los\", \"type\": [\"double\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = transferes #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert timestamp columns to datetime64[ns]\n",
    "timestamp_columns = [\"intime\", \"outtime\"]\n",
    "for col in timestamp_columns:\n",
    "    if col in df.columns:\n",
    "        # Assuming string format like 'YYYY-MM-DD HH:MM:SS'; adjust format if different\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"subject_id\", \"hadm_id\", \"icustay_id\", \"prev_wardid\", \"curr_wardid\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int32')  # Convert float to int, fill NA with 0\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"dbsource\", \"eventtype\", \"prev_careunit\", \"curr_careunit\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert los to float64 and handle missing values\n",
    "if 'los' in df.columns:\n",
    "    df['los'] = df['los'].fillna(0.0).astype('float64')  # Fill NA with 0.0\n",
    "else:\n",
    "    raise ValueError(\"Column los not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in timestamp_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"transferes.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb5907",
   "metadata": {},
   "source": [
    "### Table --> labeventes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76fe21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76074 entries, 0 to 76073\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   row_id      76074 non-null  int64  \n",
      " 1   subject_id  76074 non-null  int64  \n",
      " 2   hadm_id     61812 non-null  float64\n",
      " 3   itemid      76074 non-null  int64  \n",
      " 4   charttime   76074 non-null  object \n",
      " 5   value       76070 non-null  object \n",
      " 6   valuenum    67030 non-null  float64\n",
      " 7   valueuom    66669 non-null  object \n",
      " 8   flag        29737 non-null  object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "labeventes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 6244563, 'subject_id': 10006, 'hadm_id': 0, 'itemid': 50868, 'charttime': datetime.datetime(2164, 9, 24, 20, 21, tzinfo=datetime.timezone.utc), 'value': '19', 'valuenum': 19.0, 'valueuom': 'mEq/L', 'flag': ''}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"ChartEvent\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"subject_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"hadm_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"itemid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"charttime\", \"type\": [{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}, \"null\"]},\n",
    "        {\"name\": \"value\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"valuenum\", \"type\": [\"double\", \"null\"]},\n",
    "        {\"name\": \"valueuom\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"flag\", \"type\": [\"string\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = labeventes #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert timestamp column to datetime64[ns]\n",
    "timestamp_columns = [\"charttime\"]\n",
    "for col in timestamp_columns:\n",
    "    if col in df.columns:\n",
    "        # Assuming string format like 'YYYY-MM-DD HH:MM:SS'; adjust format if different\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"subject_id\", \"hadm_id\", \"itemid\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int32')  # Convert float to int for hadm_id\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"value\", \"valueuom\", \"flag\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert valuenum to float64 and handle missing values\n",
    "if 'valuenum' in df.columns:\n",
    "    df['valuenum'] = df['valuenum'].fillna(0.0).astype('float64')  # Fill NA with 0.0\n",
    "else:\n",
    "    raise ValueError(\"Column valuenum not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "for record in records:\n",
    "    for col in timestamp_columns:\n",
    "        if col in record and not pd.isna(record[col]):\n",
    "            record[col] = int(record[col].value // 10**6)  # Convert to milliseconds\n",
    "        else:\n",
    "            record[col] = None\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"labeventes.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa88421",
   "metadata": {},
   "source": [
    "### Table --> d_icd_dignoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33749ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_id       14567 non-null  int64 \n",
      " 1   icd9_code    14567 non-null  object\n",
      " 2   short_title  14567 non-null  object\n",
      " 3   long_title   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n"
     ]
    }
   ],
   "source": [
    "d_icd_dignoses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae800bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 1, 'icd9_code': '01716', 'short_title': 'Erythem nod tb-oth test', 'long_title': 'Erythema nodosum with hypersensitivity reaction in tuberculosis, tubercle bacilli not found by bacteriological or histological examination, but tuberculosis confirmed by other methods [inoculation of animals]'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, parse_schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"ICD9Dictionary\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"icd9_code\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"short_title\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"long_title\", \"type\": [\"string\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = d_icd_dignoses #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert integer column and handle missing values\n",
    "int_columns = [\"row_id\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"icd9_code\", \"short_title\", \"long_title\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\",\"d_icd_dignoses.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ca71b",
   "metadata": {},
   "source": [
    "### Table --> d_labitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed6f1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 753 entries, 0 to 752\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   row_id      753 non-null    int64 \n",
      " 1   itemid      753 non-null    int64 \n",
      " 2   label       753 non-null    object\n",
      " 3   fluid       753 non-null    object\n",
      " 4   category    753 non-null    object\n",
      " 5   loinc_code  585 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 35.4+ KB\n"
     ]
    }
   ],
   "source": [
    "d_labitems.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e67a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_id': 1, 'itemid': 50800, 'label': 'SPECIMEN TYPE', 'fluid': 'BLOOD', 'category': 'BLOOD GAS', 'loinc_code': ''}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastavro import writer, schema\n",
    "import os\n",
    "\n",
    "# Avro schema definition\n",
    "avro_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"ItemDictionary\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"row_id\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"itemid\", \"type\": [\"int\", \"null\"]},\n",
    "        {\"name\": \"label\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"fluid\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"category\", \"type\": [\"string\", \"null\"]},\n",
    "        {\"name\": \"loinc_code\", \"type\": [\"string\", \"null\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load and clean the data\n",
    "df = d_labitems #pd.read_csv('your_input_file.csv')  # Replace with actual file path\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert integer columns and handle missing values\n",
    "int_columns = [\"row_id\", \"itemid\"]\n",
    "for col in int_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int32')  # Fill NA with 0; adjust as needed\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert string columns and handle missing values\n",
    "string_columns = [\"label\", \"fluid\", \"category\", \"loinc_code\"]\n",
    "for col in string_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('').astype('string')  # Fill NA with empty string\n",
    "    else:\n",
    "        raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "# Convert DataFrame to records for Avro\n",
    "records = df.to_dict('records')\n",
    "\n",
    "# Write to Avro file\n",
    "parsed_schema = schema.parse_schema(avro_schema)\n",
    "output_path = os.path.join(\"C:\", \"Users\", \"ahmed\", \"OneDrive\",\"Desktop\",\"avrotest\", \"d_labitems.avro\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "with open(output_path, \"wb\") as f:\n",
    "    writer(f, parsed_schema, records)\n",
    "\n",
    "# Verify the Avro file\n",
    "from fastavro import reader\n",
    "with open(output_path, 'rb') as f:\n",
    "    for record in reader(f):\n",
    "        print(record)  # Print first record to check\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
